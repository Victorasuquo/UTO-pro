# Documentation for Document QA System

## Overview
This Python script implements a Document Question Answering (QA) system. It loads markdown documents from a specified directory, splits them into manageable chunks, generates text embeddings using the OpenAI API, stores them in a ChromaDB collection, and enables querying of these documents to generate concise answers to user questions.

## Installation & Dependencies
To set up the project, ensure the following dependencies are installed:
- `python-dotenv` for loading environment variables.
- `chromadb` for storing and managing document chunks.
- `openai` for accessing OpenAI's API for embeddings.

To install the dependencies, use:
```bash
pip install python-dotenv chromadb openai
```

Make sure to set up an `.env` file in the project directory containing your OpenAI API key:
```
OPENAI_API_KEY=your_openai_api_key
```

## Usage
To run the script, simply execute it in the terminal after ensuring the markdown documents are present in the specified directory (`./files`). The script uses `print` statements extensively to provide feedback on its progress.

### Example
```bash
python document_qa_system.py
```

## Function/Class Documentation

### `load_documents_from_directory(directory_path)`
Loads markdown documents from a specified directory.

- **Input Parameters:**
  - `directory_path` (str): Path to the directory containing the markdown documents.
  
- **Return Values:**
  - List[Dict[str, str]]: A list of dictionaries, each containing the document ID and text.

### `split_text(text, chunk_size=1000, chunk_overlap=20)`
Splits a given text into chunks of specified size with some overlap between the chunks.

- **Input Parameters:**
  - `text` (str): The text to be split.
  - `chunk_size` (int): Desired size of each chunk (default is 1000).
  - `chunk_overlap` (int): Number of overlapping characters between consecutive chunks (default is 20).
  
- **Return Values:**
  - List[str]: A list containing the split chunks of text.

### `get_openai_embedding(text)`
Generates an embedding for the provided text using the OpenAI API.

- **Input Parameters:**
  - `text` (str): The text to generate an embedding for.
  
- **Return Values:**
  - List[float]: A list of numerical values representing the embedding.

### `query_documents(question, n_results=2)`
Queries the ChromaDB for relevant document chunks based on the provided question.

- **Input Parameters:**
  - `question` (str): The question for which to find relevant documents.
  - `n_results` (int): The number of results to return (default is 2).
  
- **Return Values:**
  - List[str]: A list of relevant document chunks.

### `generate_response(question, relevant_chunks)`
Generates a concise answer based on the relevant document chunks and provided question.

- **Input Parameters:**
  - `question` (str): The question for which to generate a response.
  - `relevant_chunks` (List[str]): The context chunks to consider for generating an answer.
  
- **Return Values:**
  - str: A concise response generated by the OpenAI model.

## Code Walkthrough
1. **Environment Setup:** The script loads an API key from the environment using `dotenv`, enabling interaction with OpenAI's API.
2. **Database Initialization:** It initializes a persistent Chroma client to store document chunks.
3. **Document Loading:** The `load_documents_from_directory` function imports markdown files and reads their content into memory.
4. **Text Chunking:** The loaded documents are split into smaller pieces using the `split_text` function, allowing for efficient processing and retrieval.
5. **Embedding Generation:** For each text chunk, an embedding is generated using OpenAI's embedding function and stored alongside the chunk.
6. **Database Insertion:** The generated chunks and their embeddings are then inserted into the ChromaDB collection.
7. **Query Handling:** The `query_documents` function retrieves relevant chunks based on a user query.
8. **Response Generation:** Finally, the `generate_response` function uses the relevant chunks to form an answer, which is printed to the console.

## Example Output
Upon asking a question, the expected output is a concise response derived from the relevant chunks of documents, such as:
```
The project described in the README focuses on implementing a Document QA system that efficiently retrieves and presents information based on user queries.
```

## Error Handling
The script currently lacks explicit error handling mechanisms. However, it's advisable to implement try-except blocks around critical sections (like file reading, API calls, and database operations) to gracefully manage potential failures (e.g., file not found, API timeouts). 

Consider adding logging to record and monitor any issues that might arise during execution.